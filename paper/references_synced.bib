@inproceedings{binder_dfki-mlst_2024,
  title = {{{DFKI-MLST}} at {{DialAM-2024 Shared Task}}: {{System Description}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Binder, Arne and Anikina, Tatiana and Hennig, Leonhard and Ostermann, Simon},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {93--102},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.9},
  abstract = {This paper presents the dfki-mlst submission for the DialAM shared task (Ruiz-Dolz et al., 2024) on identification of argumentative and illocutionary relations in dialogue. Our model achieves best results in the global setting: 48.25 F1 at the focused level when looking only at the related arguments/locutions and 67.05 F1 at the general level when evaluating the complete argument maps. We describe our implementation of the data pre-processing, relation encoding and classification, evaluating 11 different base models and performing experiments with, e.g., node text combination and data augmentation. Our source code is publicly available.}
}

@incollection{budzynska_towards_2014,
  title = {Towards Argument Mining from Dialogue},
  booktitle = {Computational {{Models}} of {{Argument}}},
  author = {Budzynska, Katarzyna and Janier, Mathilde and Kang, Juyeon and Reed, Chris and {Saint-Dizier}, Patrick and Stede, Manfred and Yaskorska, Olena},
  year = {2014},
  pages = {185--196},
  publisher = {IOS Press}
}

@inproceedings{chaixanien_pungene_2024,
  title = {Pungene at {{DialAM-2024}}: {{Identification}} of {{Propositional}} and {{Illocutionary Relations}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Chaixanien, Sirawut and Choi, Eugene and Shaar, Shaden and Cardie, Claire},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {119--123},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.12},
  abstract = {In this paper we tackle the shared task DialAM-2024 aiming to annotate dialogue based on the inference anchoring theory (IAT). The task can be split into two parts, identification of propositional relations and identification of illocutionary relations. We propose a pipelined system made up of three parts: (1) locutionary-propositions relation detection, (2) propositional relations detection, and (3) illocutionary relations identification. We fine-tune models independently for each step, and combine at the end for the final system. Our proposed system ranks second overall compared to other participants in the shared task, scoring an average f1-score on both sub-parts of 63.7.}
}

@inproceedings{hautli-janisz_qt30_2022,
  title = {{{QT30}}: {{A Corpus}} of {{Argument}} and {{Conflict}} in {{Broadcast Debate}}},
  booktitle = {Proceedings of the {{Thirteenth Language Resources}} and {{Evaluation Conference}}},
  author = {{Hautli-Janisz}, Annette and Kikteva, Zlata and Siskou, Wassiliki and Gorska, Kamila and Becker, Ray and Reed, Chris},
  editor = {Calzolari, Nicoletta and B{\'e}chet, Fr{\'e}d{\'e}ric and Blache, Philippe and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, H{\'e}l{\`e}ne and Odijk, Jan and Piperidis, Stelios},
  year = {2022},
  month = jun,
  pages = {3291--3300},
  publisher = {European Language Resources Association},
  address = {Marseille, France},
  abstract = {Broadcast political debate is a core pillar of democracy: it is the public's easiest access to opinions that shape policies and enables the general public to make informed choices. With QT30, we present the largest corpus of analysed dialogical argumentation ever created (19,842 utterances, 280,000 words) and also the largest corpus of analysed broadcast political debate to date, using 30 episodes of BBC's `Question Time' from 2020 and 2021. Question Time is the prime institution in UK broadcast political debate and features questions from the public on current political issues, which are responded to by a weekly panel of five figures of UK politics and society. QT30 is highly argumentative and combines language of well-versed political rhetoric with direct, often combative, justification-seeking of the general public. QT30 is annotated with Inference Anchoring Theory, a framework well-known in argument mining, which encodes the way arguments and conflicts are created and reacted to in dialogical settings. The resource is freely available at http://corpora.aifdb.org/qt30.}
}

@article{lawrence_argument_2019,
  title = {Argument {{Mining}}: {{A Survey}}},
  author = {Lawrence, John and Reed, Chris},
  year = {2019},
  month = dec,
  journal = {Computational Linguistics},
  volume = {45},
  number = {4},
  pages = {765--818},
  publisher = {MIT Press},
  address = {Cambridge, MA},
  doi = {10.1162/coli_a_00364},
  abstract = {Argument mining is the automatic identification and extraction of the structure of inference and reasoning expressed as arguments presented in natural language. Understanding argumentative structure makes it possible to determine not only what positions people are adopting, but also why they hold the opinions they do, providing valuable insights in domains as diverse as financial market prediction and public relations. This survey explores the techniques that establish the foundations for argument mining, provides a review of recent advances in argument mining techniques, and discusses the challenges faced in automatically extracting a deeper understanding of reasoning expressed in language in general.}
}

@article{roy_learning_2002,
  title = {Learning Visually Grounded Words and Syntax for a Scene Description Task},
  author = {Roy, Deb K.},
  year = {2002},
  month = jul,
  journal = {Computer Speech \& Language},
  volume = {16},
  number = {3-4},
  pages = {353--385},
  issn = {08852308},
  doi = {10.1016/S0885-2308(02)00024-4},
  urldate = {2024-11-19},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@inproceedings{ruiz-dolz_overview_2024,
  title = {Overview of {{DialAM-2024}}: {{Argument Mining}} in {{Natural Language Dialogues}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {{Ruiz-Dolz}, Ramon and Lawrence, John and Schad, Ella and Reed, Chris},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {83--92},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.8},
  abstract = {Argumentation is the process by which humans rationally elaborate their thoughts and opinions in written (e.g., essays) or spoken (e.g., debates) contexts. Argument Mining research, however, has been focused on either written argumentation or spoken argumentation but without considering any additional information, e.g., speech acts and intentions. In this paper, we present an overview of DialAM-2024, the first shared task in dialogical argument mining, where argumentative relations and speech illocutions are modelled together in a unified framework. The task was divided into two different sub-tasks: the identification of propositional relations and the identification of illocutionary relations. Six different teams explored different methodologies to leverage both sources of information to reconstruct argument maps containing the locutions uttered in the speeches and the argumentative propositions implicit in them. The best performing team achieved an F1-score of 67.05\% in the overall evaluation of the reconstruction of complete argument maps, considering both sub-tasks included in the DialAM-2024 shared task.}
}

@inproceedings{saha_turiya_2024,
  title = {Turiya at {{DialAM-2024}}: {{Inference Anchoring Theory Based LLM Parsers}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Saha, Sougata and Srihari, Rohini},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {124--129},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.13},
  abstract = {Representing discourse as argument graphs facilitates robust analysis. Although computational frameworks for constructing graphs from monologues exist, there is a lack of frameworks for parsing dialogue. Inference Anchoring Theory (IAT) is a theoretical framework for extracting graphical argument structures and relationships from dialogues. Here, we introduce computational models for implementing the IAT framework for parsing dialogues. We experiment with a classification-based biaffine parser and Large Language Model (LLM)-based generative methods and compare them. Our results demonstrate the utility of finetuning LLMs for constructing IAT-based argument graphs from dialogues, which is a nuanced task.}
}

@incollection{simari_argument_2009,
  title = {The {{Argument Interchange Format}}},
  booktitle = {Argumentation in {{Artificial Intelligence}}},
  author = {Rahwan, Iyad and Reed, Chris},
  editor = {Simari, Guillermo and Rahwan, Iyad},
  year = {2009},
  pages = {383--402},
  publisher = {Springer US},
  address = {Boston, MA},
  doi = {10.1007/978-0-387-98197-0_19},
  urldate = {2024-11-08},
  isbn = {978-0-387-98196-3 978-0-387-98197-0},
  langid = {english}
}

@book{stede_argumentation_2019,
  title = {Argumentation Mining},
  author = {Stede, Manfred and Schneider, Jodi and Hirst, Graeme},
  year = {2019},
  publisher = {Springer}
}

@inproceedings{wu_knowcomp_2024,
  title = {{{KnowComp}} at {{DialAM-2024}}: {{Fine-tuning Pre-trained Language Models}} for {{Dialogical Argument Mining}} with {{Inference Anchoring Theory}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}}, {{DialAM}} 2024},
  author = {Wu, Yuetong and Zhou, Yukai and Xu, Baixuan and Wang, Weiqi and Song, Yangqiu},
  year = {2024}
}

@inproceedings{ye_end--end_2021,
  title = {End-to-{{End Argument Mining}} as {{Biaffine Dependency Parsing}}},
  booktitle = {Proceedings of the 16th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Main Volume}}},
  author = {Ye, Yuxiao and Teufel, Simone},
  year = {2021},
  pages = {669--678},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2021.eacl-main.55},
  urldate = {2025-01-05},
  langid = {english}
}

@inproceedings{zheng_knowcomp_2024,
  title = {{{KNOWCOMP POKEMON Team}} at {{DialAM-2024}}: {{A Two-Stage Pipeline}} for {{Detecting Relations}} in {{Dialogue Argument Mining}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Zheng, Zihao and Wang, Zhaowei and Zong, Qing and Song, Yangqiu},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {110--118},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.11},
  abstract = {Dialogue Argument Mining(DialAM) is an important branch of Argument Mining(AM). DialAM-2024 is a shared task focusing on dialogue argument mining, which requires us to identify argumentative relations and illocutionary relations among proposition nodes and locution nodes. To accomplish this, we propose a two-stage pipeline, which includes the Two-Step S-Node Prediction Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment the training data in both stages and introduce context in the prediction of Stage 2. We successfully completed the task and achieved good results. Our team KNOWCOMP POKEMON ranked 1st in the ARI Focused score and 4th in the Global Focused score.}
}
