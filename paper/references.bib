
@article{lawrence_argument_2019,
	title = {Argument {Mining}: {A} {Survey}},
	volume = {45},
	url = {https://aclanthology.org/J19-4006},
	doi = {10.1162/coli_a_00364},
	abstract = {Argument mining is the automatic identification and extraction of the structure of inference and reasoning expressed as arguments presented in natural language. Understanding argumentative structure makes it possible to determine not only what positions people are adopting, but also why they hold the opinions they do, providing valuable insights in domains as diverse as financial market prediction and public relations. This survey explores the techniques that establish the foundations for argument mining, provides a review of recent advances in argument mining techniques, and discusses the challenges faced in automatically extracting a deeper understanding of reasoning expressed in language in general.},
	number = {4},
	journal = {Computational Linguistics},
	author = {Lawrence, John and Reed, Chris},
	month = dec,
	year = {2019},
	note = {Place: Cambridge, MA
Publisher: MIT Press},
	pages = {765--818},
}

@book{stede_argumentation_2019,
	title = {Argumentation mining},
	publisher = {Springer},
	author = {Stede, Manfred and Schneider, Jodi and Hirst, Graeme},
	year = {2019},
}

@inproceedings{wu_knowcomp_2024,
	title = {{KnowComp} at {DialAM}-2024: {Fine}-tuning {Pre}-trained {Language} {Models} for {Dialogical} {Argument} {Mining} with {Inference} {Anchoring} {Theory}},
	booktitle = {Proceedings of the 11th {Workshop} on {Argument} {Mining}, {DialAM} 2024},
	author = {Wu, Yuetong and Zhou, Yukai and Xu, Baixuan and Wang, Weiqi and Song, Yangqiu},
	year = {2024},
}

@inproceedings{zheng_knowcomp_2024,
	address = {Bangkok, Thailand},
	title = {{KNOWCOMP} {POKEMON} {Team} at {DialAM}-2024: {A} {Two}-{Stage} {Pipeline} for {Detecting} {Relations} in {Dialogue} {Argument} {Mining}},
	url = {https://aclanthology.org/2024.argmining-1.11},
	doi = {10.18653/v1/2024.argmining-1.11},
	abstract = {Dialogue Argument Mining(DialAM) is an important branch of Argument Mining(AM). DialAM-2024 is a shared task focusing on dialogue argument mining, which requires us to identify argumentative relations and illocutionary relations among proposition nodes and locution nodes. To accomplish this, we propose a two-stage pipeline, which includes the Two-Step S-Node Prediction Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment the training data in both stages and introduce context in the prediction of Stage 2. We successfully completed the task and achieved good results. Our team KNOWCOMP POKEMON ranked 1st in the ARI Focused score and 4th in the Global Focused score.},
	booktitle = {Proceedings of the 11th {Workshop} on {Argument} {Mining} ({ArgMining} 2024)},
	publisher = {Association for Computational Linguistics},
	author = {Zheng, Zihao and Wang, Zhaowei and Zong, Qing and Song, Yangqiu},
	editor = {Ajjour, Yamen and Bar-Haim, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
	month = aug,
	year = {2024},
	pages = {110--118},
}

@inproceedings{chaixanien_pungene_2024,
	address = {Bangkok, Thailand},
	title = {Pungene at {DialAM}-2024: {Identification} of {Propositional} and {Illocutionary} {Relations}},
	url = {https://aclanthology.org/2024.argmining-1.12},
	doi = {10.18653/v1/2024.argmining-1.12},
	abstract = {In this paper we tackle the shared task DialAM-2024 aiming to annotate dialogue based on the inference anchoring theory (IAT). The task can be split into two parts, identification of propositional relations and identification of illocutionary relations. We propose a pipelined system made up of three parts: (1) locutionary-propositions relation detection, (2) propositional relations detection, and (3) illocutionary relations identification. We fine-tune models independently for each step, and combine at the end for the final system. Our proposed system ranks second overall compared to other participants in the shared task, scoring an average f1-score on both sub-parts of 63.7.},
	booktitle = {Proceedings of the 11th {Workshop} on {Argument} {Mining} ({ArgMining} 2024)},
	publisher = {Association for Computational Linguistics},
	author = {Chaixanien, Sirawut and Choi, Eugene and Shaar, Shaden and Cardie, Claire},
	editor = {Ajjour, Yamen and Bar-Haim, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
	month = aug,
	year = {2024},
	pages = {119--123},
}

@inproceedings{saha_turiya_2024,
	address = {Bangkok, Thailand},
	title = {Turiya at {DialAM}-2024: {Inference} {Anchoring} {Theory} {Based} {LLM} {Parsers}},
	url = {https://aclanthology.org/2024.argmining-1.13},
	doi = {10.18653/v1/2024.argmining-1.13},
	abstract = {Representing discourse as argument graphs facilitates robust analysis. Although computational frameworks for constructing graphs from monologues exist, there is a lack of frameworks for parsing dialogue. Inference Anchoring Theory (IAT) is a theoretical framework for extracting graphical argument structures and relationships from dialogues. Here, we introduce computational models for implementing the IAT framework for parsing dialogues. We experiment with a classification-based biaffine parser and Large Language Model (LLM)-based generative methods and compare them. Our results demonstrate the utility of finetuning LLMs for constructing IAT-based argument graphs from dialogues, which is a nuanced task.},
	booktitle = {Proceedings of the 11th {Workshop} on {Argument} {Mining} ({ArgMining} 2024)},
	publisher = {Association for Computational Linguistics},
	author = {Saha, Sougata and Srihari, Rohini},
	editor = {Ajjour, Yamen and Bar-Haim, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
	month = aug,
	year = {2024},
	pages = {124--129},
}

@inproceedings{binder_dfki-mlst_2024,
	address = {Bangkok, Thailand},
	title = {{DFKI}-{MLST} at {DialAM}-2024 {Shared} {Task}: {System} {Description}},
	url = {https://aclanthology.org/2024.argmining-1.9},
	doi = {10.18653/v1/2024.argmining-1.9},
	abstract = {This paper presents the dfki-mlst submission for the DialAM shared task (Ruiz-Dolz et al., 2024) on identification of argumentative and illocutionary relations in dialogue. Our model achieves best results in the global setting: 48.25 F1 at the focused level when looking only at the related arguments/locutions and 67.05 F1 at the general level when evaluating the complete argument maps. We describe our implementation of the data pre-processing, relation encoding and classification, evaluating 11 different base models and performing experiments with, e.g., node text combination and data augmentation. Our source code is publicly available.},
	booktitle = {Proceedings of the 11th {Workshop} on {Argument} {Mining} ({ArgMining} 2024)},
	publisher = {Association for Computational Linguistics},
	author = {Binder, Arne and Anikina, Tatiana and Hennig, Leonhard and Ostermann, Simon},
	editor = {Ajjour, Yamen and Bar-Haim, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
	month = aug,
	year = {2024},
	pages = {93--102},
}

@incollection{budzynska_towards_2014,
	title = {Towards argument mining from dialogue},
	booktitle = {Computational {Models} of {Argument}},
	publisher = {IOS Press},
	author = {Budzynska, Katarzyna and Janier, Mathilde and Kang, Juyeon and Reed, Chris and Saint-Dizier, Patrick and Stede, Manfred and Yaskorska, Olena},
	year = {2014},
	pages = {185--196},
}

@incollection{simari_argument_2009,
	address = {Boston, MA},
	title = {The {Argument} {Interchange} {Format}},
	isbn = {978-0-387-98196-3 978-0-387-98197-0},
	url = {https://link.springer.com/10.1007/978-0-387-98197-0_19},
	language = {en},
	urldate = {2024-11-08},
	booktitle = {Argumentation in {Artificial} {Intelligence}},
	publisher = {Springer US},
	author = {Rahwan, Iyad and Reed, Chris},
	editor = {Simari, Guillermo and Rahwan, Iyad},
	year = {2009},
	doi = {10.1007/978-0-387-98197-0_19},
	pages = {383--402},
}

@inproceedings{hautli-janisz_qt30_2022,
	address = {Marseille, France},
	title = {{QT30}: {A} {Corpus} of {Argument} and {Conflict} in {Broadcast} {Debate}},
	url = {https://aclanthology.org/2022.lrec-1.352},
	abstract = {Broadcast political debate is a core pillar of democracy: it is the public's easiest access to opinions that shape policies and enables the general public to make informed choices. With QT30, we present the largest corpus of analysed dialogical argumentation ever created (19,842 utterances, 280,000 words) and also the largest corpus of analysed broadcast political debate to date, using 30 episodes of BBC's `Question Time' from 2020 and 2021. Question Time is the prime institution in UK broadcast political debate and features questions from the public on current political issues, which are responded to by a weekly panel of five figures of UK politics and society. QT30 is highly argumentative and combines language of well-versed political rhetoric with direct, often combative, justification-seeking of the general public. QT30 is annotated with Inference Anchoring Theory, a framework well-known in argument mining, which encodes the way arguments and conflicts are created and reacted to in dialogical settings. The resource is freely available at http://corpora.aifdb.org/qt30.},
	booktitle = {Proceedings of the {Thirteenth} {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Hautli-Janisz, Annette and Kikteva, Zlata and Siskou, Wassiliki and Gorska, Kamila and Becker, Ray and Reed, Chris},
	editor = {Calzolari, Nicoletta and Béchet, Frédéric and Blache, Philippe and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, Hélène and Odijk, Jan and Piperidis, Stelios},
	month = jun,
	year = {2022},
	pages = {3291--3300},
}

@inproceedings{ruiz-dolz_overview_2024,
	address = {Bangkok, Thailand},
	title = {Overview of {DialAM}-2024: {Argument} {Mining} in {Natural} {Language} {Dialogues}},
	url = {https://aclanthology.org/2024.argmining-1.8},
	doi = {10.18653/v1/2024.argmining-1.8},
	abstract = {Argumentation is the process by which humans rationally elaborate their thoughts and opinions in written (e.g., essays) or spoken (e.g., debates) contexts. Argument Mining research, however, has been focused on either written argumentation or spoken argumentation but without considering any additional information, e.g., speech acts and intentions. In this paper, we present an overview of DialAM-2024, the first shared task in dialogical argument mining, where argumentative relations and speech illocutions are modelled together in a unified framework. The task was divided into two different sub-tasks: the identification of propositional relations and the identification of illocutionary relations. Six different teams explored different methodologies to leverage both sources of information to reconstruct argument maps containing the locutions uttered in the speeches and the argumentative propositions implicit in them. The best performing team achieved an F1-score of 67.05\% in the overall evaluation of the reconstruction of complete argument maps, considering both sub-tasks included in the DialAM-2024 shared task.},
	booktitle = {Proceedings of the 11th {Workshop} on {Argument} {Mining} ({ArgMining} 2024)},
	publisher = {Association for Computational Linguistics},
	author = {Ruiz-Dolz, Ramon and Lawrence, John and Schad, Ella and Reed, Chris},
	editor = {Ajjour, Yamen and Bar-Haim, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
	month = aug,
	year = {2024},
	pages = {83--92},
}

@inproceedings{ye_end--end_2021,
	address = {Online},
	title = {End-to-{End} {Argument} {Mining} as {Biaffine} {Dependency} {Parsing}},
	url = {https://aclanthology.org/2021.eacl-main.55},
	doi = {10.18653/v1/2021.eacl-main.55},
	abstract = {Non-neural approaches to argument mining (AM) are often pipelined and require heavy feature-engineering. In this paper, we propose a neural end-to-end approach to AM which is based on dependency parsing, in contrast to the current state-of-the-art which relies on relation extraction. Our biaffine AM dependency parser significantly outperforms the state-of-the-art, performing at F1 = 73.5\% for component identification and F1 = 46.4\% for relation identification. One of the advantages of treating AM as biaffine dependency parsing is the simple neural architecture that results. The idea of treating AM as dependency parsing is not new, but has previously been abandoned as it was lagging far behind the state-of-the-art. In a thorough analysis, we investigate the factors that contribute to the success of our model: the biaffine model itself, our representation for the dependency structure of arguments, different encoders in the biaffine model, and syntactic information additionally fed to the model. Our work demonstrates that dependency parsing for AM, an overlooked idea from the past, deserves more attention in the future.},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Ye, Yuxiao and Teufel, Simone},
	editor = {Merlo, Paola and Tiedemann, Jorg and Tsarfaty, Reut},
	month = apr,
	year = {2021},
	pages = {669--678},
}
